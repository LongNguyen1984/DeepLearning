{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "mount_file_id": "1L3R_MpZSajLBbvyBzRFyfxC2J_miLXgU",
      "authorship_tag": "ABX9TyPyvPhEwaM26WljQJ7JV6x0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LongNguyen1984/DeepLearning/blob/master/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKm7xkIJGvmW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAUV1uQSQGMR"
      },
      "source": [
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "\n",
        "def load_data(filename):\n",
        "  dataset = read_csv(filename, header=0);\n",
        "  data = dataset.values;\n",
        "  return data\n",
        "def segment_data(signal, distance, overlap):\n",
        "  i = 1;\n",
        "  s = list()\n",
        "  while int(i+distance)<signal.shape[0]:\n",
        "    a = signal[int(i):int(i+distance)];\n",
        "    #a = [x for x in t]\n",
        "    #a = DataFrame.transpose(DataFrame(t))\n",
        "    #a = np.split(a,int(distance-1)\n",
        "    s.append(a)\n",
        "    i = int(i + distance*(1-overlap))\n",
        "    \n",
        "  return np.asarray(s) # return a nd array\n",
        "\n",
        "lenW = 100\n",
        "ol = 0.5\n",
        "data = load_data('drive/My Drive/InvertPhaseLong2.csv')  \n",
        "ppg = segment_data(data[:,0],lenW, ol)\n",
        "ppg1 = segment_data(data[:,2],lenW, ol)\n",
        "#ppg2 = segment_data(data[:,1],lenW, ol)\n",
        "\n",
        "data2 = load_data('drive/My Drive/Dataset/longcunDB2.csv')\n",
        "ppg2 = segment_data(data2[:,1],lenW, ol)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8BnVRx_e8UT",
        "outputId": "9fa62d02-e8e9-42bb-9d5b-9f2dbc4aef3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# label for first group of Data\n",
        "y1 = [1]*ppg.shape[0];\n",
        "y2 = [0]*ppg1.shape[0];\n",
        "y3 = [2]*ppg2.shape[0];\n",
        "\n",
        "y1 = np.asarray(y1)\n",
        "y2 = np.asarray(y2)\n",
        "y3 = np.asarray(y3)\n",
        "\n",
        "#ydf1 = DataFrame(y1)\n",
        "#ydf2 = DataFrame(y2)\n",
        "# Concatenate data\n",
        "X = np.concatenate((ppg, ppg1,ppg2))\n",
        "y = np.concatenate((y1, y2, y3))\n",
        "print(X.shape)\n",
        "\n",
        "# rescale data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "  \n",
        "# define min max scaler\n",
        "def scaling(signal):\n",
        "  scaler = MinMaxScaler()\n",
        "  s_trans = signal.transpose()\n",
        "  Xscaled = scaler.fit_transform(s_trans)\n",
        "  Xscaled = Xscaled.transpose()\n",
        "  return Xscaled  \n",
        "# Scaling Input Data \n",
        "Xscaled = scaling(X)\n",
        "Xscaled2 = scaling(ppg2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1236, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ1UHV2bfSrx"
      },
      "source": [
        "Repearing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIbnvLaWfTeV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "# split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(Xscaled, y, test_size=0.33, random_state=5)\n",
        "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=1)\n",
        "\n",
        "#X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
        "#X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
        "# X_val = X_val.reshape((X_val.shape[0],X_val.shape[1],1))\n",
        "y_train = to_categorical(y_train, num_classes= 3)\n",
        "y_test = to_categorical(y_test, num_classes= 3)\n",
        "# y_val = to_categorical(y_val, num_classes= 3)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY9_kqZ6_mAq"
      },
      "source": [
        "# Build Model MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0aWdAo_fc2B",
        "outputId": "bdb2958b-f348-423c-931d-e38d6a4a5ece",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# lstm model for the har dataset\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "  verbose, epochs, batch_size = 0, 50, 64\n",
        "  #n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "  n_timesteps, n_outputs = X_train.shape[1], y_train.shape[1]\n",
        "  model = Sequential()\n",
        "  model.add(Dense(100, activation='relu',input_dim=n_timesteps))\n",
        "  #model.add(Dense(100, activation='relu', input_shape=(n_timesteps,n_features)))\n",
        "  model.add(Dense(200, activation='relu'))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  #model.add(Dropout(0.5))\n",
        "  #model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  history = model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  # evaluate model\n",
        "  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "  return accuracy, history\n",
        "\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "  print(scores)\n",
        "  m, s = mean(scores), std(scores)\n",
        "  print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "\n",
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "  # load data\n",
        "  #trainX, trainy, testX, testy = load_dataset()\n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for r in range(repeats):\n",
        "    \n",
        "    score, history = evaluate_model(X_train, y_train, X_test, y_test)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "  # summarize results\n",
        "  summarize_results(scores)\n",
        "  return history\n",
        "\n",
        "# run the experiment\n",
        "history = run_experiment()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">#1: 99.265\n",
            ">#2: 99.265\n",
            ">#3: 99.265\n",
            ">#4: 99.510\n",
            ">#5: 100.000\n",
            ">#6: 99.510\n",
            ">#7: 99.510\n",
            ">#8: 99.510\n",
            ">#9: 99.755\n",
            ">#10: 99.510\n",
            "[99.26470518112183, 99.26470518112183, 99.26470518112183, 99.50980544090271, 100.0, 99.50980544090271, 99.50980544090271, 99.50980544090271, 99.75489974021912, 99.50980544090271]\n",
            "Accuracy: 99.510% (+/-0.219)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ev_nnpm4eDI",
        "outputId": "79755a73-c03d-4dc7-a5c1-cf866c75e10a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "verbose, epochs, batch_size = 0, 25, 32\n",
        "#n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
        "n_timesteps, n_outputs = X_train.shape[1], y_train.shape[1]\n",
        "model = Sequential()\n",
        "#model.add(Bidirectional(LSTM(100,activation='relu'), input_shape=(n_timesteps,n_features)))\n",
        "model.add(Dense(100, activation='relu',input_dim=n_timesteps))\n",
        "  #model.add(Dense(50, activation='relu'))\n",
        "  #model.add(Dropout(0.5))\n",
        "  #model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  # evaluate model\n",
        "_, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=0)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f81f0d3a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgwkdL-s7CHI",
        "outputId": "fd2dfb85-8117-4245-a611-92b3b2e48e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(828, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n2iCPtQ45zi",
        "outputId": "fc5a63d3-da52-4311-e057-3ff08f14da90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_125\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_356 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_357 (Dense)            (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_358 (Dense)            (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 15,303\n",
            "Trainable params: 15,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slni9UOmBdnM"
      },
      "source": [
        "# K-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74IzQJeeBdIR",
        "outputId": "fa4ab09b-cecc-44a9-e5fe-6503ebc305f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, StratifiedShuffleSplit\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "num_folds = 10\n",
        "SEED = 34\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "skf = StratifiedKFold(n_splits=num_folds, random_state=SEED,shuffle=True)\n",
        "sss = StratifiedShuffleSplit(n_splits=num_folds, random_state=SEED, test_size=3)\n",
        "#Reshape X, y\n",
        "#Xrsh = Xscaled.reshape((Xscaled.shape[0],Xscaled.shape[1],1))\n",
        "#yrsh = to_categorical(y, num_classes=3)\n",
        "\n",
        "Xrsh = X_train\n",
        "yrsh = y_train\n",
        "\n",
        "# fit network\n",
        "#history = model.fit(Xrsh, yrsh, validation_split=0.33, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\n",
        "# Define per-fold score containers <-- these are new\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "fold_no = 1\n",
        "\n",
        "\n",
        "for train, test in kfold.split(Xrsh, yrsh):\n",
        "#for train, test in skf.split(Xrsh, yrsh):\n",
        "#for train, test in sss.split(Xrsh, yrsh):\n",
        "  # Build the model\n",
        "  verbose, epochs, batch_size = 1, 25, 32\n",
        "  n_timesteps, n_outputs = Xrsh.shape[1], yrsh.shape[1]\n",
        "  model = Sequential()\n",
        "  model.add(Dense(100, activation='relu',input_dim=n_timesteps))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  # Fit data to model\n",
        "  history = model.fit(Xrsh[train], yrsh[train], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  \n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(Xrsh[test], yrsh[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0141 - accuracy: 0.5208\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.7275\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6928 - accuracy: 0.7678\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.8362\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8685\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8980\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.9221\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9530\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.9705\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9611\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9812\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.9826\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0906 - accuracy: 0.9866\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9866\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9906\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9906\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9933\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9933\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0412 - accuracy: 0.9933\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9946\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9946\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9960\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9946\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9946\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9973\n",
            "Score for fold 1: loss of 0.04060272499918938; accuracy of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0612 - accuracy: 0.4859\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8795 - accuracy: 0.6940\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7172 - accuracy: 0.7463\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.8081\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8604\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.9034\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.9289\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9436\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9678\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9758\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9678\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9785\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9866\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9852\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9826\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0737 - accuracy: 0.9893\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0640 - accuracy: 0.9879\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9919\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9893\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9906\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9946\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9973\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9960\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9973\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9987\n",
            "Score for fold 2: loss of 0.03930732235312462; accuracy of 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0026 - accuracy: 0.5517\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8632 - accuracy: 0.6470\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7252 - accuracy: 0.7664\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.8322\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8846\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3450 - accuracy: 0.9034\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9342\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9570\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1724 - accuracy: 0.9597\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9624\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9745\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9812\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9866\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9893\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9906\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9919\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9893\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9933\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9960\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9879\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9973\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9933\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9973\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9987\n",
            "Score for fold 3: loss of 0.07796911150217056; accuracy of 97.59036302566528%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0187 - accuracy: 0.5638\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8446 - accuracy: 0.7423\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7051 - accuracy: 0.7946\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.8362\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8872\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3637 - accuracy: 0.9235\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2910 - accuracy: 0.9356\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.9423\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9624\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9678\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1414 - accuracy: 0.9624\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.9812\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9839\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9866\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9906\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9893\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9919\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9960\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9906\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9960\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0337 - accuracy: 0.9973\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9960\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9973\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9960\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_test_function.<locals>.test_function at 0x7f81f2618510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 4: loss of 0.1275930106639862; accuracy of 95.18072009086609%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.5705\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7979 - accuracy: 0.6940\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.8081\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.8456\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8940\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.3242 - accuracy: 0.9101\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2537 - accuracy: 0.9409\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2041 - accuracy: 0.9624\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9718\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9745\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9826\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9772\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9893\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.9866\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9866\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9919\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0462 - accuracy: 0.9933\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9919\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9919\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9933\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9933\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9960\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9973\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9946\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9960\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f81fd1a4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 5: loss of 0.0328495129942894; accuracy of 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0327 - accuracy: 0.4872\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8502 - accuracy: 0.7463\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.8054\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8617\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.9087\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2930 - accuracy: 0.9235\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9530\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.9503\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1520 - accuracy: 0.9705\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9705\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.9758\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9826\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9879\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0749 - accuracy: 0.9866\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9919\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0571 - accuracy: 0.9893\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9933\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9919\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 0.9933\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0316 - accuracy: 0.9960\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9973\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9973\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9987\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9973\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9960\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f81f4922400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 6: loss of 0.07596822828054428; accuracy of 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 1.0083 - accuracy: 0.4805\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.8127 - accuracy: 0.7409\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.8282\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8658\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.9060\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2935 - accuracy: 0.9396\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2296 - accuracy: 0.9490\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.9557\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1536 - accuracy: 0.9745\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1297 - accuracy: 0.9785\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9812\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0924 - accuracy: 0.9839\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9906\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9852\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9906\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9866\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0466 - accuracy: 0.9946\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9933\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9960\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9987\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9987\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9973\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9973\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9987\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9987\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8200a861e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 7: loss of 0.038244567811489105; accuracy of 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 1.0506 - accuracy: 0.4510\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.8760 - accuracy: 0.7034\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.7906\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.8255\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.8846\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3367 - accuracy: 0.9208\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2814 - accuracy: 0.9235\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.9477\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.9678\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9772\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1108 - accuracy: 0.9839\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9852\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9893\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0762 - accuracy: 0.9852\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9906\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0520 - accuracy: 0.9906\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9826\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9866\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9933\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9906\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9933\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9973\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9973\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9987\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9973\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8200aa6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 8: loss of 0.02703605592250824; accuracy of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.9792 - accuracy: 0.5442\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.7879 - accuracy: 0.7413\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6076 - accuracy: 0.8391\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.8660\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.9075\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2682 - accuracy: 0.9477\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9598\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9732\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1307 - accuracy: 0.9826\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.1069 - accuracy: 0.9853\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0969 - accuracy: 0.9799\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9866\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9906\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9906\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9893\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9946\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9920\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9933\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9946\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9960\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9946\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9987\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9987\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9987\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f8200e727b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 9: loss of 0.013804016634821892; accuracy of 100.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 1.0436 - accuracy: 0.4718\n",
            "Epoch 2/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.8818 - accuracy: 0.7265\n",
            "Epoch 3/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.7223 - accuracy: 0.8097\n",
            "Epoch 4/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.8566\n",
            "Epoch 5/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4444 - accuracy: 0.8727\n",
            "Epoch 6/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.9236\n",
            "Epoch 7/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 0.9357\n",
            "Epoch 8/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.9531\n",
            "Epoch 9/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9531\n",
            "Epoch 10/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9692\n",
            "Epoch 11/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9812\n",
            "Epoch 12/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9772\n",
            "Epoch 13/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9853\n",
            "Epoch 14/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9866\n",
            "Epoch 15/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9839\n",
            "Epoch 16/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9879\n",
            "Epoch 17/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9866\n",
            "Epoch 18/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9893\n",
            "Epoch 19/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9920\n",
            "Epoch 20/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9946\n",
            "Epoch 21/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9973\n",
            "Epoch 22/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9960\n",
            "Epoch 23/25\n",
            "24/24 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9973\n",
            "Epoch 24/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f81f5733840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Score for fold 10: loss of 0.07175671309232712; accuracy of 98.78048896789551%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.04060272499918938 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.03930732235312462 - Accuracy: 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.07796911150217056 - Accuracy: 97.59036302566528%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.1275930106639862 - Accuracy: 95.18072009086609%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.0328495129942894 - Accuracy: 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.07596822828054428 - Accuracy: 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.038244567811489105 - Accuracy: 98.79518151283264%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.02703605592250824 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.013804016634821892 - Accuracy: 100.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.07175671309232712 - Accuracy: 98.78048896789551%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 98.67322981357574 (+- 1.3682900065529138)\n",
            "> Loss: 0.05451312642544508\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mgPx8f6CXl6",
        "outputId": "82da61c2-1826-4500-e1a9-ac456965fa00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy= model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9902\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}